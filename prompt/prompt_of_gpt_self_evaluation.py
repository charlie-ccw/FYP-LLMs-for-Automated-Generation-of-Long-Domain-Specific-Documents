GPT_SELF_EVALUATION_SYSTEM = "You are an excellent evaluator."

GPT_SELF_EVALUATION_PROMPT = """Below I will give you a template requirement, a target text, and a text generated by the model. I need you to compare the model's generated text with the target text and provide a score.
NOTE:
    1. The scoring range is 0-1, with higher scores indicating better-generated text.
    2. (0 to 0.4) is bad, (0.4 to 0.6) is considered passing, (0.6 to 0.8) is excellent, (0.8 to 1) is outstanding. Please refine your scores to three decimal places.
    3. Please provide a comprehensive score based on the following four aspects: 
        - the fluency of the generated text;
        - grammar;
        - whether it includes the key content of the target text;
        - whether it conforms to the writing template;
    4. Output in JSON format:
        {{
            "reason": "The reason why you gave this score",
            "score": The final score of the model's generated text, in FLOAT format
        }}

# TEMPLATE REQUIREMENT:
{template_requirement}

# TARGET TEXT:
{target_text}

# GENERATED TEXT BY MODEL:
{generation_text}
"""
